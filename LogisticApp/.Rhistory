bed_type,
property_type,
host_is_superhost) %>%
mutate(review_scores_rating=ifelse(is.na(review_scores_rating),
median(review_scores_rating,na.rm=T),
review_scores_rating)) %>%
ungroup()
mydata[is.na(mydata$review_scores_rating), "review_scores_rating"] <- median(mydata$review_scores_rating, na.rm = T)
Appartment <- c("Aparthotel","Serviced apartment", "Loft",
"Condominium", "Apartment")
House <- c("Barn", "Dome house", "Lighthouse", "Houseboat",
"Treehouse", "Earth house", "Cottage", "Tiny house",
"Townhouse", "House", "Cabin","Villa")
Shared_room <- c("Dorm", "Hostel", "Guesthouse", "Timeshare")
Private_room <- c("Farm stay", "Bed and breakfast", "Resort", "Hotel",
"Boutique hotel", "Guest suite", "In-law")
Other <- c("Bungalow", "Train", "Bus", "Boat", "Other", "Cave", "Island",
"Camper/RV", "Yurt", "Castle", "Tent", "Casa particular (Cuba)")
mydata$property_type <- as.character(mydata$property_type)
mydata <-
mutate(mydata,
property_type = ifelse(property_type %in% Appartment,
"Appartment", property_type),
property_type = ifelse(property_type %in% House,
"House", property_type),
property_type = ifelse(property_type %in% Shared_room,
"SharedRoom", property_type),
property_type = ifelse(property_type %in% Private_room,
"PrivateRoom", property_type),
property_type = ifelse(property_type %in% Other,
"Others", property_type))
mydata <- mydata[!mydata$property_type=="Others",]
mydata <- mydata[!mydata$property_type=="SharedRoom",]
mydata$cancellation_policy <- as.character(mydata$cancellation_policy)
mydata <- mutate(mydata,
cancellation_policy =
ifelse(cancellation_policy=="strict_14_with_grace_period",
"strict", cancellation_policy),
cancellation_policy =
ifelse(cancellation_policy=="super_strict_30",
"strict", cancellation_policy),
cancellation_policy =
ifelse(cancellation_policy=="super_strict_60",
"strict", cancellation_policy))
mydata <- mydata[,-which(names(mydata) == "bed_type")]
mydata <- mutate(mydata,
host_is_superhost = ifelse(host_is_superhost=="t",
"True", "False"))
colnames(mydata)[which(names(mydata) == "neighbourhood_group_cleansed")] <- "neighborhood"
mydata <- select(mydata, -id)
mydata <- mutate_if(mydata, is.character, as.factor)
write.csv(mydata, "clean_data.csv", row.names = FALSE)
# Data management packages
library(dplyr)
library(forcats)
library(modelsummary)
# Plotting packages
library(ggplot2)
library(RColorBrewer)
library(purrr)
library(rattle)
library(ggcorrplot)
# Model fitting packages
library(rpart)
library(caret)
library(leaps)
library(ModelMetrics)
# Nice presentation of results
library(knitr)
library(papeR)
library(xtable)
library(kableExtra)
# Import the downloaded data
files <- read.csv("https://raw.githubusercontent.com/lavergnetse/Data/master/listings.csv", sep = ",")
# Select the columns we want to keep from the initial listings csv files
listings_keep <- c("id", "price", "host_is_superhost",
"neighbourhood_group_cleansed",
"latitude","longitude", "property_type", "accommodates",
"bedrooms", "beds", "bed_type", "cleaning_fee",
"minimum_nights", "availability_365",
"review_scores_rating","cancellation_policy")
listings <- files[,listings_keep]
listings <- listings[!duplicated(listings$id),]
listings <- listings[complete.cases(listings$id),]
listings$price <- as.numeric(gsub("[\\$,]", "", listings$price))
listings$cleaning_fee <- as.numeric(gsub("[\\$,]", "", listings$cleaning_fee))
listings$host_is_superhost[listings$host_is_superhost==""] <- NA
listings <- listings %>% filter(accommodates >= beds)
mydata <- listings
mydata <- mydata %>%
group_by(
property_type,
accommodates) %>%
mutate(bedrooms=ifelse(is.na(bedrooms),
median(bedrooms,na.rm = T),bedrooms)) %>%
ungroup()
mydata[is.na(mydata$cleaning_fee), "cleaning_fee"] <- 0
mydata[is.na(mydata$cleaning_fee), "cleaning_fee"] <- 0
mydata[is.na(mydata$host_is_superhost),"host_is_superhost"] <- "f"
mydata <- mydata %>%
group_by(neighbourhood_group_cleansed,
bed_type,
property_type,
host_is_superhost) %>%
mutate(review_scores_rating=ifelse(is.na(review_scores_rating),
median(review_scores_rating,na.rm=T),
review_scores_rating)) %>%
ungroup()
mydata[is.na(mydata$review_scores_rating), "review_scores_rating"] <- median(mydata$review_scores_rating, na.rm = T)
Appartment <- c("Aparthotel","Serviced apartment", "Loft",
"Condominium", "Apartment")
House <- c("Barn", "Dome house", "Lighthouse", "Houseboat",
"Treehouse", "Earth house", "Cottage", "Tiny house",
"Townhouse", "House", "Cabin","Villa")
Shared_room <- c("Dorm", "Hostel", "Guesthouse", "Timeshare")
Private_room <- c("Farm stay", "Bed and breakfast", "Resort", "Hotel",
"Boutique hotel", "Guest suite", "In-law")
Other <- c("Bungalow", "Train", "Bus", "Boat", "Other", "Cave", "Island",
"Camper/RV", "Yurt", "Castle", "Tent", "Casa particular (Cuba)")
mydata$property_type <- as.character(mydata$property_type)
mydata <-
mutate(mydata,
property_type = ifelse(property_type %in% Appartment,
"Appartment", property_type),
property_type = ifelse(property_type %in% House,
"House", property_type),
property_type = ifelse(property_type %in% Shared_room,
"SharedRoom", property_type),
property_type = ifelse(property_type %in% Private_room,
"PrivateRoom", property_type),
property_type = ifelse(property_type %in% Other,
"Others", property_type))
mydata <- mydata[!mydata$property_type=="Others",]
mydata <- mydata[!mydata$property_type=="SharedRoom",]
mydata$cancellation_policy <- as.character(mydata$cancellation_policy)
mydata <- mutate(mydata,
cancellation_policy =
ifelse(cancellation_policy=="strict_14_with_grace_period",
"strict", cancellation_policy),
cancellation_policy =
ifelse(cancellation_policy=="super_strict_30",
"strict", cancellation_policy),
cancellation_policy =
ifelse(cancellation_policy=="super_strict_60",
"strict", cancellation_policy))
mydata <- mydata[,-which(names(mydata) == "bed_type")]
mydata <- mutate(mydata,
host_is_superhost = ifelse(host_is_superhost=="t",
"True", "False"))
colnames(mydata)[which(names(mydata) == "neighbourhood_group_cleansed")] <- "neighborhood"
mydata <- select(mydata, -id)
mydata <- mutate_if(mydata, is.character, as.factor)
write.csv(mydata, "clean_data.csv", row.names = FALSE)
# Data management packages
library(dplyr)
library(forcats)
library(modelsummary)
# Plotting packages
library(ggplot2)
library(RColorBrewer)
library(purrr)
library(rattle)
library(ggcorrplot)
# Model fitting packages
library(rpart)
library(caret)
library(leaps)
library(ModelMetrics)
# Nice presentation of results
library(knitr)
library(papeR)
library(xtable)
library(kableExtra)
# Import the downloaded data
files <- read.csv("https://raw.githubusercontent.com/lavergnetse/Data/master/listings.csv", sep = ",")
# Select the columns we want to keep from the initial listings csv files
listings_keep <- c("id", "price", "host_is_superhost",
"neighbourhood_group_cleansed",
"latitude","longitude", "property_type", "accommodates",
"bedrooms", "beds", "bed_type", "cleaning_fee",
"minimum_nights", "availability_365",
"review_scores_rating","cancellation_policy")
listings <- files[,listings_keep]
listings <- listings[!duplicated(listings$id),]
listings <- listings[complete.cases(listings$id),]
listings$price <- as.numeric(gsub("[\\$,]", "", listings$price))
listings$cleaning_fee <- as.numeric(gsub("[\\$,]", "", listings$cleaning_fee))
listings$host_is_superhost[listings$host_is_superhost==""] <- NA
listings <- listings %>% filter(accommodates >= beds)
mydata <- listings
mydata <- mydata %>%
group_by(
property_type,
accommodates) %>%
mutate(bedrooms=ifelse(is.na(bedrooms),
median(bedrooms,na.rm = T),bedrooms)) %>%
ungroup()
mydata[is.na(mydata$cleaning_fee), "cleaning_fee"] <- 0
mydata[is.na(mydata$cleaning_fee), "cleaning_fee"] <- 0
mydata[is.na(mydata$host_is_superhost),"host_is_superhost"] <- "f"
mydata <- mydata %>%
group_by(neighbourhood_group_cleansed,
bed_type,
property_type,
host_is_superhost) %>%
mutate(review_scores_rating=ifelse(is.na(review_scores_rating),
median(review_scores_rating,na.rm=T),
review_scores_rating)) %>%
ungroup()
mydata[is.na(mydata$review_scores_rating), "review_scores_rating"] <- median(mydata$review_scores_rating, na.rm = T)
Appartment <- c("Aparthotel","Serviced apartment", "Loft",
"Condominium", "Apartment")
House <- c("Barn", "Dome house", "Lighthouse", "Houseboat",
"Treehouse", "Earth house", "Cottage", "Tiny house",
"Townhouse", "House", "Cabin","Villa")
Shared_room <- c("Dorm", "Hostel", "Guesthouse", "Timeshare")
Private_room <- c("Farm stay", "Bed and breakfast", "Resort", "Hotel",
"Boutique hotel", "Guest suite", "In-law")
Other <- c("Bungalow", "Train", "Bus", "Boat", "Other", "Cave", "Island",
"Camper/RV", "Yurt", "Castle", "Tent", "Casa particular (Cuba)")
mydata$property_type <- as.character(mydata$property_type)
mydata <-
mutate(mydata,
property_type = ifelse(property_type %in% Appartment,
"Appartment", property_type),
property_type = ifelse(property_type %in% House,
"House", property_type),
property_type = ifelse(property_type %in% Shared_room,
"SharedRoom", property_type),
property_type = ifelse(property_type %in% Private_room,
"PrivateRoom", property_type),
property_type = ifelse(property_type %in% Other,
"Others", property_type))
mydata <- mydata[!mydata$property_type=="Others",]
mydata <- mydata[!mydata$property_type=="SharedRoom",]
mydata$cancellation_policy <- as.character(mydata$cancellation_policy)
mydata <- mutate(mydata,
cancellation_policy =
ifelse(cancellation_policy=="strict_14_with_grace_period",
"strict", cancellation_policy),
cancellation_policy =
ifelse(cancellation_policy=="super_strict_30",
"strict", cancellation_policy),
cancellation_policy =
ifelse(cancellation_policy=="super_strict_60",
"strict", cancellation_policy))
mydata <- mydata[,-which(names(mydata) == "bed_type")]
mydata <- mutate(mydata,
host_is_superhost = ifelse(host_is_superhost=="t",
"True", "False"))
colnames(mydata)[which(names(mydata) == "neighbourhood_group_cleansed")] <- "neighborhood"
mydata <- select(mydata, -id)
mydata <- mutate_if(mydata, is.character, as.factor)
write.csv(mydata, "clean_data.csv", row.names = FALSE)
knitr::opts_chunk$set( message = FALSE, warning = FALSE, results =TRUE, echo = TRUE)
library(knitr)
opts_chunk$set(warning = FALSE, message = FALSE,
autodep = TRUE, tidy = FALSE, cache = TRUE)
#opts_chunk$set(cache.rebuild=TRUE)
# My colors:
SIAP.color <- "#0385a8"
# Data management packages
library(dplyr)
library(forcats)
library(modelsummary)
# Plotting packages
library(ggplot2)
library(RColorBrewer)
library(purrr)
library(rattle)
library(ggcorrplot)
# Model fitting packages
library(rpart)
library(caret)
library(leaps)
library(ModelMetrics)
# Nice presentation of results
library(knitr)
library(papeR)
library(xtable)
library(kableExtra)
# Sets up parallel computing for more efficient training
library(parallel)
nrcore <- detectCores()
cl <- parallel::makeCluster(nrcore-2, setup_strategy = "sequential")
library(doParallel)
registerDoParallel(cl)
df <- read.csv("clean_data.csv")
df <- select(df, -id)
knitr::opts_chunk$set( message = FALSE, warning = FALSE, results =TRUE, echo = TRUE)
library(knitr)
opts_chunk$set(warning = FALSE, message = FALSE,
autodep = TRUE, tidy = FALSE, cache = TRUE)
#opts_chunk$set(cache.rebuild=TRUE)
# My colors:
SIAP.color <- "#0385a8"
# Data management packages
library(dplyr)
library(forcats)
library(modelsummary)
# Plotting packages
library(ggplot2)
library(RColorBrewer)
library(purrr)
library(rattle)
library(ggcorrplot)
# Model fitting packages
library(rpart)
library(caret)
library(leaps)
library(ModelMetrics)
# Nice presentation of results
library(knitr)
library(papeR)
library(xtable)
library(kableExtra)
# Sets up parallel computing for more efficient training
library(parallel)
nrcore <- detectCores()
cl <- parallel::makeCluster(nrcore-2, setup_strategy = "sequential")
library(doParallel)
registerDoParallel(cl)
df <- read.csv("clean_data.csv")
# function to set up random seeds
setSeeds <- function(method = "cv",
numbers = 1, repeats = 1,
tunes = NULL, seed = 123)
{
#B is the number of resamples and integer vector
# of M (numbers + tune length if any)
B <- if (method == "cv") numbers
else if(method == "repeatedcv") numbers * repeats
else NULL
if(is.null(length)) {
seeds <- NULL
} else {
set.seed(seed = seed)
seeds <- vector(mode = "list", length = B)
seeds <-
lapply(seeds, function(x)
sample.int(n = 1000000,
size = numbers + ifelse(is.null(tunes),
0, tunes)))
seeds[[length(seeds) + 1]] <-
sample.int(n = 1000000, size = 1)
}
# return seeds
seeds
}
datasummary_skim(df, type = "categorical" )
datasummary_skim(df, type = "numeric")
numeric <- select_if(df, is.numeric)
# We compute the correlation matrix of the covariates
corr_coef<-cor(numeric ,use = "p")
#And then plot it with nice options
ggcorrplot(corr_coef,
type = "lower",         # lower triangle of the matrix only
hc.order = TRUE,        # variable sorted from highest to lowest
outline.col = "white",  #Color options
lab = TRUE) + ggtitle("Correlation between numerical variables")
summary(df)
# Splits data into training and testing sets
set.seed(777)
trainIndex <- createDataPartition(df$price, p = 0.5, list = FALSE, times = 1)
train_data <- df[trainIndex,]
validation_data  <- df[-trainIndex,]
# Scale the training and test data based on the training data mean and variance.
ScalingValues <- preProcess(train_data, method = c("center", "scale"))
train_data <- predict(ScalingValues, train_data)
validation_data <- predict(ScalingValues, validation_data)
# Control variables
numbers <- 5
repeats <- 20
rcvTunes <- 10 # tune number of models
seed <- 123
# repeated cross validation
rcvSeeds <- setSeeds(method = "repeatedcv",
numbers = numbers, repeats = repeats,
tunes = rcvTunes, seed = seed)
# Controls for the CV
rcvControl <- trainControl(method = "repeatedcv",
number = numbers, repeats = repeats,
seeds = rcvSeeds)
set.seed(123)
lasso_fit <- train(price ~ .,
data = train_data,
method = "glmnet",
tuneGrid = expand.grid(alpha = 1,
# the search for an optimal lambda can be changed to reduce training time, by creating a smaller
# grid to search
lambda = seq(0, 0.003, 0.0001)),
trControl = rcvControl)
ggplot(lasso_fit)   +
ggtitle("Lasso Penalization") +
labs(x = "Regularization parameter (Lambda)")+
theme_minimal()
cbind(lasso_fit$bestTune$lambda,
-log(lasso_fit$bestTune$lambda)/log(10))  %>%
kable(digits=3, col.names = c("lambda (exp)", "lambda (true)")) %>%
kable_styling()
theme_models <-  theme_minimal()+ theme(plot.title = element_text(hjust = 0.5),
legend.position = "none")
lasso_varImp <- data.frame(variables = row.names(varImp(lasso_fit)$importance), varImp(lasso_fit)$importance)
# Below we set that we only show feature importances with a value larger than 3
# You can lower this if you want to see more variables, or increase it if you want to see fewer.
threshold = 2
lasso_varImp <- lasso_varImp[lasso_varImp$Overall > threshold,]
ggplot(data = lasso_varImp, mapping = aes(x=reorder(variables, Overall),
y=Overall,
fill=variables)) +
coord_flip() + geom_bar(stat = "identity", position = "dodge") +
theme_models +
labs(x = "", y = "") +
ggtitle("Feature Importance Lasso Regression")
lasso_preds <- predict(lasso_fit, validation_data)
rmse(actual = validation_data$price, predicted = lasso_preds)
# Training this model may take some time.
# Change the formula below:
rf_fit <- train(price ~ property_type + neighborhood + accommodates + bedrooms + cancellation_policy + cleaning_fee,
data = train_data,
method = "rf",
ntree = 100)
rf_fit
rf_preds <- predict(rf_fit, validation_data)
rmse(actual = validation_data$price, predicted = rf_preds)
theme_models <-  theme_minimal()+ theme(plot.title = element_text(hjust = 0.5),
legend.position = "none")
rf_varImp <- data.frame(variables = row.names(varImp(rf_fit)$importance), varImp(rf_fit)$importance)
ggplot(data = rf_varImp, mapping = aes(x=reorder(variables, Overall),
y=Overall,
fill=variables)) +
coord_flip() + geom_bar(stat = "identity", position = "dodge") +
theme_models +
labs(x = "", y = "") +
ggtitle("Feature Importance Random Forest")
knitr::knit_exit()
# Training this model may take some time.
# Change the formula below:
#rf_fit_opt <- train(price ~ .,
data = train_data,
data(mtcars)
df <-mtcars
df$cat <- as.factor(ifelse(mtcars$vs == 1, "A", "B"))
df$hp <- -(400-mtcars$hp)
t0 <- 0.9
Log_Fit2 <- glm(cat ~ hp, df, family = binomial)
preds <- as.factor(ifelse(predict(Log_Fit2, type="response") > t0 , "A", "B"))
confusionMatrix(preds, df$cat)
library(caret)
confusionMatrix(preds, df$cat)
t0 <- 0.1
Log_Fit2 <- glm(cat ~ hp, df, family = binomial)
preds <- as.factor(ifelse(predict(Log_Fit2, type="response") > t0 , "A", "B"))
confusionMatrix(preds, df$cat)
data(mtcars)
df <-mtcars
library(caret)
df$cat <- as.factor(ifelse(mtcars$vs == 1, "A", "B"))
df$hp <- -(400-mtcars$hp)
t0 <- 0.2
Log_Fit2 <- glm(cat ~ hp, df, family = binomial)
preds <- as.factor(ifelse(predict(Log_Fit2, type="response") > t0 , "A", "B"))
confusionMatrix(preds, df$cat)
data(mtcars)
df <-mtcars
library(caret)
df$cat <- as.factor(ifelse(mtcars$vs == 1, "A", "B"))
df$hp <- -(400-mtcars$hp)
t0 <- 0.2
Log_Fit2 <- glm(cat ~ hp, df, family = binomial)
preds <- as.factor(ifelse(predict(Log_Fit2, type="response") > t0 , "A", "B"))
#confusionMatrix(preds, df$cat)
preds
table(df$cat, preds)
confusionMatrix(preds, df$cat)
table(Reference = df$cat, prediction = preds)
table(prediction = preds, Reference = df$cat)
t0 <- 0.5
Log_Fit2 <- glm(cat ~ hp, df, family = binomial)
preds <- as.factor(ifelse(predict(Log_Fit2, type="response") > t0 , "A", "B"))
table(prediction = preds, Reference = df$cat)
confusionMatrix(preds, df$cat)
predtable <- table(prediction = preds, Reference = df$cat)
sensitivity <- table[1,1]
sensitivity <- table[1]
predtable[1,1]
sensitivity <- predtable[1,1]/(predtable[1,1] + predtable[2,1])
specificity <- predtable[2,2]/(predtable[2,2] + predtable[1,2])
accuracy <- (predtable[1,1] + predtable[2,2]) / (predtable[1,1] + predtable[2,1]) + (predtable[2,2] + predtable[1,2])
accuracy <- (predtable[1,1] + predtable[2,2]) / ((predtable[1,1] + predtable[2,1]) + (predtable[2,2] + predtable[1,2]))
Kappa <- (Accuracy-0.5)/(1-0.5)
Accuracy <- (predtable[1,1] + predtable[2,2]) / ((predtable[1,1] + predtable[2,1]) + (predtable[2,2] + predtable[1,2]))
Sensitivity <- predtable[1,1]/(predtable[1,1] + predtable[2,1])
Specificity <- predtable[2,2]/(predtable[2,2] + predtable[1,2])
Kappa <- (Accuracy-0.5)/(1-0.5)
t0 <- 0.2
Log_Fit2 <- glm(cat ~ hp, df, family = binomial)
preds <- as.factor(ifelse(predict(Log_Fit2, type="response") > t0 , "A", "B"))
predtable <- table(prediction = preds, Reference = df$cat)
Accuracy <- (predtable[1,1] + predtable[2,2]) / ((predtable[1,1] + predtable[2,1]) + (predtable[2,2] + predtable[1,2]))
Sensitivity <- predtable[1,1]/(predtable[1,1] + predtable[2,1])
Specificity <- predtable[2,2]/(predtable[2,2] + predtable[1,2])
Kappa <- (Accuracy-0.5)/(1-0.5)
confusionMatrix(Log_Fit2)
confusionMatrix(preds, df$cat)
Kappa <- (Accuracy-(sum(df$cat == "A")/length(df$cat)))/(1-0.5)
confusionMatrix(preds, df$cat)
Kappa <- (Accuracy-(sum(df$cat == "A")/length(df$cat)))/(1-(sum(df$cat == "A")/length(df$cat)))
confusionMatrix(preds, df$cat)
predtable
shiny::runApp('C:/Users/Patrick/Desktop/UN/ML_Course/UNML/LogisticExplore')
shiny::runApp()
